{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Merge compounds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "suffix = ''  # suffix for analysis\n",
    "hit_filename = 'hits.filtered.sdf'\n",
    "pdb_filename = 'reference.pdb'\n",
    "ranking = '∆∆G' #@param [\"LE\", \"∆∆G\", \"comRMSD\"]\n",
    "joining_cutoff:int = 5\n",
    "quick_reananimation:bool = False\n",
    "output_folder = 'frag_output'\n",
    "sw_dist = 25\n",
    "sw_length = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe475cf-da4b-404f-9be9-006b2b78bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, PandasTools, BRICS\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import pandas as pd\n",
    "import pandera.typing as pdt\n",
    "from typing import List, Dict\n",
    "\n",
    "with Chem.SDMolSupplier(hit_filename) as sd:\n",
    "    hits: Dict[str, Chem.Mol] = {mol.GetProp('_Name'): mol for mol in sd}\n",
    "    \n",
    "    \n",
    "with open(pdb_filename) as fh:\n",
    "    pdbblock = fh.read()\n",
    "    \n",
    "# ------------------------------------------------------\n",
    "    \n",
    "import logging\n",
    "import pyrosetta_help as ph\n",
    "\n",
    "logger = ph.configure_logger()\n",
    "logger.handlers[0].setLevel(logging.ERROR)  # logging.WARNING = 30\n",
    "\n",
    "from fragmenstein import Igor\n",
    "\n",
    "Igor.init_pyrosetta()\n",
    "# # Equivalent to:\n",
    "# import pyrosetta\n",
    "# extra_options = ph.make_option_string(no_optH=False,\n",
    "#                                       ex1=None,\n",
    "#                                       ex2=None,\n",
    "#                                       #mute='all',\n",
    "#                                       ignore_unrecognized_res=True,\n",
    "#                                       load_PDB_components=False,\n",
    "#                                       ignore_waters=True)\n",
    "# pyrosetta.init(extra_options=extra_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12a488-8152-49d5-b46b-8e93a6763e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(output_folder):\n",
    "    # isnt this done automatically?\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "import os, re\n",
    "import pyrosetta, logging\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from fragmenstein import Victor, Laboratory\n",
    "\n",
    "Victor.work_path = output_folder\n",
    "Victor.monster_throw_on_discard = True  # stop this merger if a fragment cannot be used.\n",
    "Victor.monster_joining_cutoff = joining_cutoff  # Å\n",
    "Victor.quick_reanimation = quick_reananimation  # for the impatient\n",
    "Victor.error_to_catch = Exception  # stop the whole laboratory otherwise\n",
    "#Victor.enable_stdout(logging.ERROR)\n",
    "Victor.enable_logfile(os.path.join(output_folder, 'fragmenstein.log'), logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ffe8c-b0a0-48ca-bbc2-288fa0c322c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time\n",
    "from rdkit import Chem, rdBase\n",
    "\n",
    "# calculate!\n",
    "lab = Laboratory(pdbblock=pdbblock, covalent_resi=None)\n",
    "n_cores = 55  #@param {type:\"integer\"}\n",
    "hitlist = list(hits.values())\n",
    "\n",
    "tick = time.time()\n",
    "combinations:pd.DataFrame = lab.combine(hitlist, n_cores=n_cores)\n",
    "with rdBase.BlockLogs():\n",
    "    combinations['simple_smiles'] = combinations.unminimized_mol.apply(Victor.to_simple_smiles)\n",
    "combinations.to_pickle(f'fragmenstein_mergers{suffix}.pkl.gz')\n",
    "combinations.to_csv(f'fragmenstein_mergers{suffix}.csv')\n",
    "print(tick - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483e960-d6b7-4555-a19a-922212aa4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(combinations.loc[(combinations['∆∆G'] < 0) & (combinations.outcome == 'acceptable')], '∆∆G', title='Distribution of ∆∆G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265ff84-d038-4b9c-bf71-76b28692572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smallworld_api import SmallWorld\n",
    "from warnings import warn\n",
    "\n",
    "sws = SmallWorld()\n",
    "\n",
    "chemical_databases:pd.DataFrame = sws.retrieve_databases()\n",
    "\n",
    "queries = combinations.sort_values(ranking).loc[(combinations.outcome == 'acceptable')].drop_duplicates('simple_smiles').reset_index().head(500)\n",
    "\n",
    "similars = sws.search_many(queries.simple_smiles.to_list(),\n",
    "                           dist=sw_dist,\n",
    "                           length=sw_length,\n",
    "                           db=sws.REAL_dataset,\n",
    "                           tolerated_exceptions=Exception)\n",
    "# query_index was added clientside to keep track!\n",
    "similars['query_name'] = similars.query_index.map( queries.name.to_dict() )\n",
    "similars['hits'] = similars.query_index.map( queries.hit_mols.to_dict() )\n",
    "similars['minimized_merger'] = similars.query_index.map( queries.minimized_mol.to_dict() )\n",
    "similars['unminimized_merger'] = similars.query_index.map( queries.unminimized_mol.to_dict() )\n",
    "similars['name'] = similars['id'] + ':' + similars['query_name']\n",
    "similars['smiles'] = similars.hitSmiles.str.split(expand=True)[0]\n",
    "similars.to_pickle(f'similars{suffix}.pkl.gz')\n",
    "print(f'Found {len(similars)} analogues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_custom_map(row: pd.Series) -> Dict[str, Dict[int, int]]:\n",
    "    \"\"\"\n",
    "    SmallWorld returns a mapping of the indices.\n",
    "    This functions maps the indices back to the original hit molecules.\n",
    "    :param row:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    temp = Victor(row.hits, pdb_block=pdbblock)\n",
    "    temp.monster.positioned_mol = row.unminimized_merger\n",
    "    temp.minimized_mol = row.minimized_merger\n",
    "    return temp.migrate_sw_origins(row)\n",
    "\n",
    "similars['custom_map'] = similars.apply(get_custom_map, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882ad58-7129-4009-a511-3666ae5011cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, PandasTools, BRICS\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import pandas as pd\n",
    "import pandera.typing as pdt\n",
    "from typing import List, Dict\n",
    "    \n",
    "# ------------------------------------------------------\n",
    "    \n",
    "import logging\n",
    "import pyrosetta_help as ph\n",
    "import pyrosetta\n",
    "\n",
    "ranking = '∆∆G' #@param [\"LE\", \"∆∆G\", \"comRMSD\"]\n",
    "joining_cutoff:int = 5\n",
    "quick_reananimation:bool = False\n",
    "output_folder = 'frag_output'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(output_folder):\n",
    "    # isnt this done automatically?\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "import os, re\n",
    "import pyrosetta, logging\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from fragmenstein import Victor, Laboratory\n",
    "\n",
    "Victor.work_path = output_folder\n",
    "Victor.monster_throw_on_discard = False  # unmin + hits combo\n",
    "Victor.monster_joining_cutoff = joining_cutoff  # Å\n",
    "Victor.quick_reanimation = quick_reananimation  # for the impatient\n",
    "Victor.error_to_catch = Exception  # stop the whole laboratory otherwise\n",
    "#Victor.enable_stdout(logging.ERROR)\n",
    "Victor.enable_logfile(os.path.join(output_folder, 'fragmenstein.log'), logging.ERROR)\n",
    "\n",
    "from fragmenstein.laboratory.validator import place_input_validator\n",
    "\n",
    "n_cores = 55\n",
    "\n",
    "lab = Laboratory(pdbblock=pdbblock, covalent_resi=None)\n",
    "placements:pd.DataFrame = lab.place(place_input_validator(similars), n_cores=n_cores)\n",
    "placements.loc[(placements['∆∆G'] > -1) & (placements.outcome == 'acceptable'), 'outcome'] = 'weak'\n",
    "placements['unminimized_mol'] = placements.unminimized_mol.fillna(Chem.Mol())\n",
    "placements.to_pickle(f'placed{suffix}.pkl.gz')\n",
    "placements.to_csv(f'placed{suffix}.csv')\n",
    "placements.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8254389-60c0-457c-bb35-dadc54a3123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(placements.loc[(placements['∆∆G'] < 0) & (placements.outcome == 'acceptable')], '∆∆G', title='Distribution of ∆∆G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77351c52-3feb-4d41-a865-5ec72f13496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, operator\n",
    "\n",
    "def split_name(name):\n",
    "    if not name:\n",
    "        return ('','')\n",
    "    if 'PV-' in name:\n",
    "        match = re.match(r'(PV-\\d+)-(.*)-(.*)', name).groups()\n",
    "    else:\n",
    "        match = re.match(r'(Z\\d+)-(.*)-(.*)', name).groups()\n",
    "    return (match[0], f\"{match[1]}-{match[2]}\" )\n",
    "\n",
    "names = placements['name'].apply(split_name)\n",
    "\n",
    "placements['enamine_name'] = names.apply(operator.itemgetter(0))\n",
    "placements['merger_name'] = names.apply(operator.itemgetter(1))\n",
    "\n",
    "# -----------------\n",
    "\n",
    "n2mol = combinations.minimized_mol.to_dict()\n",
    "# there seems to be some name bleaching? if so:\n",
    "#n2mol = dict(zip([n.replace('_', '-') for n in n2mol.keys()], n2mol.values()))\n",
    "placements['merger_mol'] = placements.merger_name.map(n2mol)\n",
    "\n",
    "placements['hit_names'] = placements.merger_name.str.split('-')\n",
    "placements['LE'] = placements.LE.abs()\n",
    "placements['path'] = placements.name.apply(lambda n: Path('frag_output') / n / f'{n}.holo_minimised.pdb')\n",
    "\n",
    "placements.to_pickle(f'placed{suffix}.pkl.gz')\n",
    "placements.to_csv(f'placed{suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4c763-5ccc-4575-a2d1-caf95e85fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids = placements.loc[placements.outcome == 'acceptable'].sort_values('∆∆G')\n",
    "valids['combined_name'] = valids['name']\n",
    "valids['name'] = valids['enamine_name']\n",
    "\n",
    "valids.to_pickle(f'acceptables{suffix}.pkl.gz')\n",
    "\n",
    "valids.path.apply(Path.exists).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1834a-6279-4714-9b46-ef077f957bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/matteoferla/PLIP-PyRosetta-hotspots-test/blob/main/plipspots_docking/plipspots/serial.py\n",
    "\n",
    "This is a class I use to _apply_ PLIP to a pd.Series of molecules.\n",
    "It is not built for the project, but works.\n",
    "Note I have not dumped the methods that are not needed for the project.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "from functools import singledispatchmethod\n",
    "from typing import Tuple, Dict, List, Union\n",
    "from collections import Counter, defaultdict\n",
    "from plip.structure.preparation import PDBComplex, PLInteraction\n",
    "from openbabel.pybel import Atom, Residue\n",
    "from openbabel.pybel import ob\n",
    "from fragmenstein.victor import MinimalPDBParser\n",
    "import warnings\n",
    "\n",
    "\n",
    "class SerialPLIPper:\n",
    "    \"\"\"\n",
    "    Calling the instance will return a ``Dict[Tuple[str, str, int], int]``,\n",
    "    where the key is interaction type, residue 3-letter name, residue index\n",
    "    and the value is the count of interactions.\n",
    "    Basically, applying Plip to a pd.Series of Chem.Mol.\n",
    "\n",
    "    Unplacking it is kind of wierd, the best way I reckon is a brutal for-loop:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        import pandas as pd\n",
    "        import pandera.typing as pdt\n",
    "\n",
    "        intxndexes: pdt.Series[Dict[Tuple[str, str, int], int]] = hits.ROMol.apply(SerialPLIPper(pdb_filename))\n",
    "        # columns will still be a tuple...:\n",
    "        intxn_df = pd.DataFrame(intxndexes.to_list()).fillna(0).astype(int)\n",
    "        hits['N_interactions'] = intxn_df.sum(axis='columns')\n",
    "        for c in sorted(intxn_df.columns, key=lambda kv: kv[2]):\n",
    "            # columns will be a colon-separated string:\n",
    "            hits[':'.join(map(str, c))] = intxn_df[c]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pdb_block: str, resn='LIG', chain='B'):\n",
    "        assert 'ATOM' in pdb_block, f'No ATOM entry in block provided: {pdb_block}'\n",
    "        self.pdb_block = pdb_block\n",
    "        self.resn = resn\n",
    "        self.chain = chain\n",
    "\n",
    "    @classmethod\n",
    "    def from_filename(cls, pdb_filename: str, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        The main constructor is from PDB block, this is from PDB file\n",
    "        \"\"\"\n",
    "        with open(pdb_filename, 'r') as f:\n",
    "            pdb_block = f.read()\n",
    "        return cls(pdb_block, *args, **kwargs)\n",
    "\n",
    "    def __call__(self, mol) -> Dict[Tuple[str, str, int], int]:\n",
    "        if mol is None or not isinstance(mol, Chem.Mol) or mol.GetNumAtoms() == 0:\n",
    "            return {}\n",
    "        holo: str = self.plonk(mol)\n",
    "        interaction_set: PLInteraction = self.get_interaction_set(holo)\n",
    "        return self.get_interaction_counts(interaction_set)\n",
    "\n",
    "    def assign_pdb(self, mol: Chem.Mol):\n",
    "        \"\"\"\n",
    "        Fix the PDB info for the molecule, in place\n",
    "        \"\"\"\n",
    "        counts = defaultdict(int)\n",
    "        atom: Chem.Atom\n",
    "        for atom in mol.GetAtoms():\n",
    "            element: str = atom.GetSymbol()\n",
    "            counts[element] += 1\n",
    "            info = Chem.AtomPDBResidueInfo(atomName=f'{element: >2}{counts[element]: <2}',\n",
    "                                           residueName=self.resn,\n",
    "                                           residueNumber=1, chainId=self.chain)\n",
    "            atom.SetPDBResidueInfo(info)\n",
    "\n",
    "    def plonk(self, mol):\n",
    "        \"\"\"\n",
    "        Temporarily here. Do not copy.\n",
    "        There likely is a way to do this in OBabel\n",
    "        This is using Fragmenstein ``MinimalPDBParser``.\n",
    "\n",
    "        :param mol:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pdbdata = MinimalPDBParser(self.pdb_block, remove_other_hetatms=True, ligname=self.resn)\n",
    "        self.assign_pdb(mol)\n",
    "        moldata = MinimalPDBParser(Chem.MolToPDBBlock(mol))\n",
    "        pdbdata.append(moldata)\n",
    "        return str(pdbdata)\n",
    "\n",
    "    @singledispatchmethod\n",
    "    def get_interaction_set(self) -> PLInteraction:\n",
    "        \"\"\"\n",
    "        Overloaded method: block or mol return the iternaction set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @get_interaction_set.register\n",
    "    def _(self, block: str) -> PLInteraction:\n",
    "        holo = PDBComplex()\n",
    "        holo.load_pdb(block, as_string=True)\n",
    "        holo.analyze()\n",
    "        return holo.interaction_sets[':'.join([self.resn, self.chain, str(1)])]\n",
    "\n",
    "    @get_interaction_set.register\n",
    "    def _(self, mol: Chem.Mol) -> PLInteraction:\n",
    "        if mol.GetNumAtoms() == 0:\n",
    "            raise ValueError('Molecule has no atoms')\n",
    "        holo = PDBComplex()\n",
    "        holo.load_pdb(self.plonk(mol), as_string=True)\n",
    "        holo.analyze()\n",
    "        return holo.interaction_sets[':'.join([self.resn, self.chain, str(1)])]\n",
    "\n",
    "    def get_atomname(self, atom: Union[Atom, ob.OBAtom]) -> str:\n",
    "        \"\"\"\n",
    "        Given an atom, return its name.\n",
    "        \"\"\"\n",
    "        if isinstance(atom, Atom):\n",
    "            res: ob.OBResidue = atom.residue.OBResidue\n",
    "            obatom = atom.OBAtom\n",
    "        elif isinstance(atom, ob.OBAtom):\n",
    "            obatom: ob.OBAtom = atom\n",
    "            res: ob.OBResidue = obatom.GetResidue()\n",
    "        else:\n",
    "            raise TypeError\n",
    "        return res.GetAtomID(obatom)\n",
    "\n",
    "    def get_atom_by_atomname(self, residue: Union[ob.OBResidue, Residue], atomname: str) -> ob.OBAtom:\n",
    "        \"\"\"\n",
    "        Get an atom by its name in a residue.\n",
    "        \"\"\"\n",
    "        if isinstance(residue, Residue):\n",
    "            residue = residue.OBResidue\n",
    "        obatom: ob.OBAtom\n",
    "        for obatom in ob.OBResidueAtomIter(residue):\n",
    "            if residue.GetAtomID(obatom).strip() == atomname:\n",
    "                return obatom\n",
    "        else:\n",
    "            raise ValueError(f'No atom with name {atomname} in residue {residue.GetName()}')\n",
    "\n",
    "    def get_interaction_counts(self, interaction_set: PLInteraction) -> Dict[Tuple[str, str, int], int]:\n",
    "        \"\"\"\n",
    "        Count the number of interactions of each type for each residue\n",
    "        \"\"\"\n",
    "        intxns: List = interaction_set.all_itypes\n",
    "        intxn_dex = defaultdict(int)\n",
    "        for intxn in intxns:\n",
    "            key = (intxn.__class__.__name__, intxn.restype, intxn.resnr)\n",
    "            intxn_dex[key] += 1\n",
    "        return dict(sorted(intxn_dex.items(), key=lambda kv: kv[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b70180-4354-4d6b-a94f-bf2f9c7a84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_check = {l[21:26].strip() for l in valids.iloc[0].path.read_text().split('\\n') if ' LIG ' in l} - {'LIG'}\n",
    "print(chain_check)\n",
    "chain = next(iter(chain_check)).split()[0]\n",
    "\n",
    "import operator\n",
    "\n",
    "plipper = SerialPLIPper('ATOM', resn='LIG', chain=chain)\n",
    "def get_intxns(path: Path) -> dict:\n",
    "    interaction_set: PLInteraction = plipper.get_interaction_set(path.read_text())\n",
    "    return plipper.get_interaction_counts(interaction_set)\n",
    "\n",
    "intxns = valids.path.apply(get_intxns)\n",
    "key_order = sorted(set(intxns.apply(lambda d: list(d.keys())).sum()), key=operator.itemgetter(2))\n",
    "for key in key_order:\n",
    "    valids[key] = intxns.apply(lambda d: d.get(key, 0))\n",
    "valids['N_interactions'] = valids[key_order].sum(axis=1)\n",
    "\n",
    "valids.to_pickle(f'acceptables{suffix}.pkl.gz')\n",
    "valids[['name', 'regarded', 'smiles', '∆∆G', '∆G_bound', '∆G_unbound',\n",
    "       'comRMSD', 'N_constrained_atoms', 'N_unconstrained_atoms', 'runtime',\n",
    "       'LE',  'outcome',\n",
    "       'percent_hybrid', 'N_interactions'] + key_order].to_csv(f'interactions{suffix}.csv')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd5f81-347a-458b-a7f7-387a9f4e092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.sort_values('∆∆G').head(20)[['∆∆G', 'name','merger_name', 'comRMSD', 'N_constrained_atoms', 'N_unconstrained_atoms', 'N_interactions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13deb1-c1ea-4f01-97e1-600fb0a05718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "short = combinations.loc[(combinations.outcome == 'acceptable')].sort_values('∆∆G').reset_index().drop_duplicates('name')\n",
    "\n",
    "PandasTools.WriteSDF(df=short,\n",
    "                    out=f'combinations{suffix}.sdf',\n",
    "                    molColName='minimized_mol',\n",
    "                    idName='name',\n",
    "                    properties=['regarded', 'smiles', '∆∆G', '∆G_bound', '∆G_unbound',\n",
    "       'comRMSD', 'N_constrained_atoms', 'N_unconstrained_atoms', 'runtime',\n",
    "       'LE',  'outcome',\n",
    "       'percent_hybrid']\n",
    "                    )\n",
    "\n",
    "short[['name', 'regarded', 'smiles', '∆∆G', '∆G_bound', '∆G_unbound',\n",
    "       'comRMSD', 'N_constrained_atoms', 'N_unconstrained_atoms', 'runtime',\n",
    "       'LE',  'outcome',\n",
    "       'percent_hybrid']].to_csv(f'combinations{suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abec73-7050-43aa-a606-2461962a9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "placements['regarded'] = placements.merger_name.str.split('-')\n",
    "short = placements.loc[(placements.outcome == 'acceptable')].sort_values('∆∆G').drop_duplicates('name')\n",
    "\n",
    "PandasTools.WriteSDF(df=short,\n",
    "                    out=f'placements{suffix}.sdf',\n",
    "                    molColName='minimized_mol',\n",
    "                    idName='name',\n",
    "                    properties=['regarded', 'merger_name', 'smiles', '∆∆G', '∆G_bound', '∆G_unbound',\n",
    "       'comRMSD', 'N_constrained_atoms', 'N_unconstrained_atoms', 'runtime',\n",
    "       'LE',  'outcome',\n",
    "       'percent_hybrid']\n",
    "                    )\n",
    "\n",
    "short[['name', 'regarded', 'smiles', '∆∆G', '∆G_bound', '∆G_unbound',\n",
    "       'comRMSD', 'N_constrained_atoms', 'N_unconstrained_atoms', 'runtime',\n",
    "       'LE',  'outcome',\n",
    "       'percent_hybrid']].to_csv(f'placements{suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7038e5-2ec3-4381-8e47-59805b7961c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids['merger_mol'] = valids.merger_name.map(placements.set_index('merger_name').minimized_mol.to_dict().get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec0e88-e8fc-4acb-86cc-ecc7ffebd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.hit_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068a769-0050-488b-8d8c-4d58d7457883",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids = valids.loc[~valids.merger_mol.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13f82c-40d0-4563-8b34-976d843c52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unbleach(names: list, fluff_marker = '§'):\n",
    "#     return [f'{names[0]}_{names[1]}{fluff_marker}{names[2]}',\n",
    "#             f'{names[3]}_{names[4]}{fluff_marker}{names[5]}',\n",
    "#            ]\n",
    "\n",
    "def unbleach(names: list, fluff_marker = '§'):\n",
    "    if len(names) < 3:\n",
    "        return names\n",
    "    if len(names) == 6:\n",
    "        return [f'{names[0]}_{names[1]}{fluff_marker}{names[2]}',\n",
    "                f'{names[3]}_{names[4]}{fluff_marker}{names[5]}',\n",
    "               ]\n",
    "    if len(names[1]) < 3:\n",
    "        return [f'{names[0]}_{names[1]}{fluff_marker}{names[2]}',\n",
    "                f'{names[3]}',\n",
    "               ]\n",
    "    if len(names[2]) < 3:\n",
    "        return [f'{names[0]}',\n",
    "                f'{names[1]}_{names[2]}{fluff_marker}{names[3]}'\n",
    "               ]\n",
    "    else:\n",
    "        raise Exception(names)\n",
    "        \n",
    "valids['hit_names'] = valids.hit_names.apply(unbleach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131a82e-dae8-4d6c-8e2c-11b0847b421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from michelanglo_api import MikeAPI\n",
    "from rdkit import Chem\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# declare variables\n",
    "hit_filename = 'EV-D68_hits.sdf'\n",
    "hit_names = list(hits.keys())\n",
    "with Chem.SDWriter(str(Path('upload') / hit_filename)) as sdfh:\n",
    "    for name, hit in hits.items():\n",
    "        hit.SetProp('_Name', name)\n",
    "        sdfh.write(hit)\n",
    "        \n",
    "headers = ['name', 'hits', 'RMSD', '∆∆G', 'LE', 'N unconstrained atoms', 'N constrained atoms', 'N interactions', 'SMILES']\n",
    "metadata: pd.DataFrame = valids.loc[~valids.merger_mol.isna()]\\\n",
    "                               .rename(columns=dict(hit_names='hits', \n",
    "                                                    comRMSD='RMSD',\n",
    "                                                    dist='distance',\n",
    "                                                    smiles='SMILES',\n",
    "                                                    N_constrained_atoms='N constrained atoms',\n",
    "                                                    N_unconstrained_atoms='N unconstrained atoms',\n",
    "                                                    N_interactions='N interactions'))[headers]\n",
    "metadata_filename: str = 'EV-D68_metadata.json'\n",
    "\n",
    "for k in ('∆∆G', 'LE', 'RMSD'):\n",
    "    metadata[k] = metadata[k].fillna(999).astype(float).round(1)\n",
    "for k in ('N unconstrained atoms',):\n",
    "    metadata[k] = metadata[k].fillna(-1).astype(int)\n",
    "metadata = metadata.copy()\n",
    "\n",
    "\n",
    "base_url = 'https://www.stats.ox.ac.uk/~ferla/mols/'  # base url path\n",
    "uuid = '5066835a-a2df-4723-ad92-5adfa622cd74' # uuid of the page target\n",
    "\n",
    "combo_filename = 'EV-D68_combinations.sdf'\n",
    "with Chem.SDWriter('upload/'+ combo_filename) as sdw:\n",
    "    combo_names = []\n",
    "    for i, row in valids.iterrows():\n",
    "        if not isinstance(row.merger_mol, Chem.Mol):\n",
    "            continue\n",
    "        row.merger_mol.SetProp('_Name', row.merger_name)\n",
    "        if row.merger_mol.GetNumAtoms() == 0:\n",
    "            continue\n",
    "        #AllChem.SanitizeMol(row.merger_mol)\n",
    "        sdw.write(row.merger_mol)\n",
    "        # odd way but hey:\n",
    "        combo_names.append(row['name'])\n",
    "\n",
    "placement_filename = 'EV-D68_placements.sdf'\n",
    "with Chem.SDWriter('upload/'+ placement_filename) as sdw:\n",
    "    placement_names = []\n",
    "    for i, row in valids.iterrows():\n",
    "        if not isinstance(row.minimized_mol, Chem.Mol):\n",
    "            continue\n",
    "        row.minimized_mol.SetProp('_Name', row['name'])\n",
    "        if row.minimized_mol.GetNumAtoms() == 0:\n",
    "            continue\n",
    "        #AllChem.SanitizeMol(row.minimized_mol)\n",
    "        sdw.write(row.minimized_mol)\n",
    "        placement_names.append(row['name'])\n",
    "        \n",
    "with open('upload/'+ metadata_filename, 'w') as fh:\n",
    "    json.dump(dict(\n",
    "                   headers=headers,\n",
    "                   data=metadata.values.tolist(),\n",
    "                   modelnamedex={'combination': combo_names,\n",
    "                                 'placement': placement_names,\n",
    "                                },\n",
    "                   hitnames=hit_names,\n",
    "            ), fh)\n",
    "    \n",
    "# make a page\n",
    "\n",
    "mike = MikeAPI()\n",
    "page = mike.get_page(uuid)\n",
    "\n",
    "page.loadfun = page.get_fragment_js(hit_sdf_url=base_url+hit_filename,\n",
    "                               model_sdf_urldex={'combination': base_url+combo_filename,\n",
    "                                                 'placement' : base_url+placement_filename,\n",
    "                                                },\n",
    "                               metadata_url=base_url+metadata_filename,\n",
    "                               model_colordex={'combination': 'salmon',\n",
    "                                               'placement': 'cyan'},\n",
    "                               hit_color='grey',\n",
    "                               template_color='gainsboro',\n",
    "                               name_col_idx = headers.index('name'),\n",
    "                               hit_col_idx = headers.index('hits'),\n",
    "                               target_col_idx = -1, # headers.index('target')\n",
    "                               sort_col = headers.index('N interactions'),\n",
    "                               sort_dir = 'desc',\n",
    "                               fun_name ='loadTable')\n",
    "\n",
    "# create a way to load the protein\n",
    "# laziest: \n",
    "#page.loadfun += 'setTimeout(loadTable, 1000)'\n",
    "# better:\n",
    "page.loadfun += \"\"\"\n",
    "window.loadprotein = (prot) => {prot.removeAllRepresentations(); \n",
    "                                prot.addRepresentation('cartoon');\n",
    "                                prot.addRepresentation('line');\n",
    "                                prot.autoView(); \n",
    "                                prot.setName('template');\n",
    "                                loadTable(); \n",
    "                                }\n",
    "\"\"\"\n",
    "page.loadfun = page.loadfun.replace('\"model_colordex\": {\"combination\": \"teal\", \"placement\": \"teal\"}',\n",
    "                                    '\"model_colordex\": {\"combination\": \"salmon\", \"placement\": \"turquoise\"}'\n",
    "                                   )\n",
    "page.proteins[0]['loadFx'] = 'loadprotein'\n",
    "page.title = 'EV-D68 3C protease followups via Fragmenstein'\n",
    "page.description = f'## Predicted followups\\nCombinations in salmon and their purchasable analogue from Enamine Real in turquoise.\\n\\n Data in table is for make-on-demand analogues. Protein is constant for the sake of memory, but induced fit may have repacked the protein in specific case hence the odd case of calculated nice score and visual clashes.\\n\\nRMSD cutoff loosened to 2Å'\n",
    "page.columns_text = 6\n",
    "page.commit()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c5883-c7af-4e42-a61e-b95f1c3e5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.sort_values('∆∆G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeab20b-8062-4aed-8606-36a2513242e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a2969-5470-4b96-b699-e050ee50d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(Chem.MolToSmiles(valids.set_index('name').loc['Z2602896888'].minimized_mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8aef0-710a-4e4e-b473-1b40fc273c86",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ('hbond', 'VAL', 162),\n",
    " # ('hbond', 'GLY', 163),\n",
    " # ('hbond', 'GLY', 164),\n",
    "\n",
    "\n",
    "valids.loc[valids[[('halogenbond', 'VAL', 162),\n",
    " ('halogenbond', 'GLY', 163),\n",
    " ('halogenbond', 'GLY', 164),\n",
    " ('halogenbond', 'ASN', 165),\n",
    "]].sum(axis=1).astype(bool)].sort_values('∆∆G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2965222-a8cd-470c-b2d3-7bd66c720cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = dict(S2=('x1083_0A§1', 'x1305_0B§1', 'x1247_0A§1'),\n",
    "S1=('x0789_0A§1',\n",
    " 'x0980_0B§1',\n",
    " 'x1604_0A§1',\n",
    " 'x1594_0A§1',\n",
    " 'x0147_0A§1',\n",
    " 'x0771_0A§1','x0771benzo', 'x0771_1A§1','x1604base', 'x1604amino', 'x1604hydroxyl',\n",
    "         'x1498_0A§1','x1498_1B§1', 'x1498_0B§1','x1537_0A§1','x1285§1B',\n",
    "          'ZINC000000080837', 'ZINC000000168472', 'ZINC000012397068', 'ZINC000015042097', 'ZINC000017061891', 'ZINC000001669068', 'ZINC000001674121', 'ZINC000019779146', 'ZINC000224485041', 'ZINC000238711097', 'ZINC000025924635', 'ZINC000026033116', 'ZINC000002289036', 'ZINC000003852685', 'ZINC000039191805', 'ZINC000045921422', 'ZINC000051951618', 'ZINC000005933792', 'ZINC000066323473', 'ZINC000066347860', 'ZINC000072187487', 'ZINC000072482101', 'ZINC000079065151', 'ZINC000082372119', 'ZINC000082372152', 'ZINC000095830806'\n",
    "         ),\n",
    "far_ridge = ('x1285_0B§2', 'x1454_0B§1', 'x1020_0A§1'),\n",
    "S_1 = ('x0232_0B§3', 'x1453_0B§2', 'x0232_0B§3', 'x0232_1B§3'),\n",
    "ridge = ('x1052_0A§2', 'x1052_1A§2','x1285_1B§2', 'x1140_0A§1', 'fippedSulfonamide'),\n",
    "waters = ( \n",
    "       'HOH219','HOH240','HOH318','HOH319','HOH322','HOH323','HOH325', 'HOH67', 'trappedHOH', 'oxyanionHOH'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce4f29-81a5-4e5b-9f89-5d4135bb0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_locs = {k: l for l, ks in locations.items() for k in ks}\n",
    "valids['locs'] = valids.hit_names.apply(lambda m: tuple(sorted([flipped_locs[m[0]], flipped_locs[m[1]]])) )\n",
    "valids = valids.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149ebbc-2cd0-42af-90a7-e9629e673426",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.locs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edbad6-28dc-4a26-a92f-2b1beb7a7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.loc[valids['∆∆G'] < -5].sort_values('N_unconstrained_atoms').drop_duplicates('locs')[['name', 'locs', 'smiles', '∆∆G', 'comRMSD','N_constrained_atoms',\n",
    "                                                  'N_unconstrained_atoms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e210952-7372-40d2-b388-e1db86fcd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_intxns = pd.read_csv('hit-intxns.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0be77a-c963-48b3-80e1-4218dba91c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change tuple columns to colon separated string columns\n",
    "valids = valids.rename(columns={col: ':'.join(map(str, col)) for col in valids.columns if isinstance(col, tuple)})\n",
    "valids = valids.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08641d-0af5-49c2-b1ca-ebc60a485741",
   "metadata": {},
   "outputs": [],
   "source": [
    "name2intxns: Dict[str, List[str]] = {n: [xn for xn, xc in xs.items() if xc and xn != 'N_interactions'] for n, xs in hit_intxns.to_dict(orient='index').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1b75c-fbb3-4caa-b431-567032f0e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def tally_hit_intxns(row: pd.Series):\n",
    "    for hit_name in row.hit_names:\n",
    "        present_tally = 0\n",
    "        absent_tally = 0\n",
    "        for intxn_name in name2intxns[hit_name]:\n",
    "            if intxn_name not in row.index:\n",
    "                print(f'missing {intxn_name}')\n",
    "                absent_tally += 1\n",
    "            elif row[intxn_name] == 0:\n",
    "                absent_tally += 1\n",
    "            else:\n",
    "                present_tally += 1\n",
    "    return (present_tally, absent_tally)\n",
    "                \n",
    "\n",
    "hit_checks = valids.apply(tally_hit_intxns, axis=1)\n",
    "valids['N_interactions_kept'] = hit_checks.apply(operator.itemgetter(0))\n",
    "valids['N_interactions_lost'] = hit_checks.apply(operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a5049-28fb-4362-b45f-e8cda6499137",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids[['name', 'N_interactions', 'N_interactions_kept', 'N_interactions_lost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31602dc-3b0d-4017-8e55-ebd9bb801765",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids['N_rotatable_bonds'] = valids.minimized_mol.apply(AllChem.CalcNumRotatableBonds)\n",
    "valids['N_HA'] = valids.minimized_mol.apply(AllChem.CalcNumHeavyAtoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bbfe3-fc22-465a-9c98-94fdf1c53a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator as rdfpg\n",
    "\n",
    "\n",
    "fpgen = rdfpg.GetRDKitFPGenerator()\n",
    "hit2fp = {name: fpgen.GetFingerprint(h) for name, h in hits.items()}\n",
    "\n",
    "def get_similarity(row):\n",
    "    fp = fpgen.GetFingerprint(AllChem.RemoveHs(row.minimized_mol))\n",
    "    return max([DataStructs.TanimotoSimilarity(fp,hit2fp[name]) for name in row.hit_names])\n",
    "\n",
    "valids['max_hit_Tanimoto'] = valids.apply(get_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca49603f-b659-4ffb-94ab-4b33a46ed904",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('N_rotatable_bonds', 'max_hit_Tanimoto', 'LE', 'N_interactions', 'N_HA', 'N_interactions_kept', 'N_interactions_lost'):\n",
    "    px.histogram(valids, col, title=col).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718e0e5-6cff-42ec-a1fe-ef3d2bf97be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit.Chem import PandasTools, Draw\n",
    "from rdkit import DataStructs\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from rdkit.Chem import rdMolDescriptors as rdmd\n",
    "from rdkit.Chem import Descriptors\n",
    "from IPython.display import HTML\n",
    "\n",
    "def butina_cluster(mol_list,cutoff=0.35):\n",
    "    # https://github.com/PatWalters/workshop/blob/master/clustering/taylor_butina.ipynb\n",
    "    fp_list = [rdmd.GetMorganFingerprintAsBitVect(AllChem.RemoveAllHs(m), 3, nBits=2048) for m in mol_list]\n",
    "    dists = []\n",
    "    nfps = len(fp_list)\n",
    "    for i in range(1,nfps):\n",
    "        sims = DataStructs.BulkTanimotoSimilarity(fp_list[i],fp_list[:i])\n",
    "        dists.extend([1-x for x in sims])\n",
    "    mol_clusters = Butina.ClusterData(dists,nfps,cutoff,isDistData=True)\n",
    "    cluster_id_list = [0]*nfps\n",
    "    for idx,cluster in enumerate(mol_clusters,1):\n",
    "        for member in cluster:\n",
    "            cluster_id_list[member] = idx\n",
    "    return cluster_id_list\n",
    "\n",
    "valids['cluster'] = butina_cluster(valids.minimized_mol.to_list())\n",
    "print(valids['cluster'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae5516-c811-4f4f-becd-aacb1b216127",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = valids.set_index('name').loc['Z1694701639']\n",
    "display2d = lambda mol: display(Chem.MolFromSmiles(Chem.MolToSmiles(AllChem.RemoveHs(mol))))\n",
    "display2d(row.minimized_mol)\n",
    "display2d(row.hit_mols[0])\n",
    "row.max_hit_Tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bfbb9-94bb-4ca9-bd99-6479e8a4b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids['filtered'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ff06f-1254-416f-b349-d0eee77fc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "rota_mask = valids['N_rotatable_bonds'] <= 3\n",
    "LE_mask = valids['LE'] >= 0.2\n",
    "intxn_mask = valids['N_interactions'] >= 3\n",
    "ddg_mask = valids['∆∆G'] <= -5\n",
    "lost_mask = valids['N_interactions_lost'] == 0\n",
    "no_hit_copies_mask = valids['max_hit_Tanimoto'] <= 0.4\n",
    "fewer_unconstrained_atoms = valids['N_unconstrained_atoms'] < valids['N_constrained_atoms']\n",
    "\n",
    "# , ascending=False\n",
    "filtered = valids.loc[rota_mask & LE_mask & intxn_mask & ddg_mask & lost_mask & no_hit_copies_mask].sort_values('N_interactions', ascending=False)\n",
    "print(len(filtered))\n",
    "filtered[['name', '∆∆G', 'LE', 'comRMSD', 'N_rotatable_bonds', 'N_interactions', 'N_HA', 'locs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd4902-ba91-4ac9-b77f-d64d7f770bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.loc[filtered.drop_duplicates('cluster').index, 'filtered'] = True\n",
    "valids.filtered.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33b667-c031-4ce0-acb9-448f4de5a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = {'N_rotatable_bonds': 1,\n",
    "           'LE': -0.2, \n",
    "           'N_interactions': -4,\n",
    "           'N_interactions_lost': +0.1,  # zero would raise error ...\n",
    "           '∆∆G': 3,\n",
    "           'N_unconstrained_atoms': 1/3,\n",
    "           'max_hit_Tanimoto': 0.4\n",
    "          }\n",
    "\n",
    "def weight_split(row):\n",
    "    return [round(row[col] / w, 1) for col, w in weights.items()]\n",
    "\n",
    "def penalize(row):\n",
    "    penalty = 0\n",
    "    for col, w in weights.items():\n",
    "        penalty += row[col] / w\n",
    "    return penalty\n",
    "\n",
    "valids['ad_hoc_penalty'] = valids.apply(penalize, axis=1)\n",
    "#valids['_split'] = valids.apply(weight_split, axis=1)\n",
    "f = valids.sort_values('ad_hoc_penalty').drop_duplicates('cluster')\n",
    "print(len(f))\n",
    "\n",
    "f.drop_duplicates('locs')[['name', 'hit_names', 'ad_hoc_penalty', 'locs', '∆∆G', 'LE', 'comRMSD', 'N_unconstrained_atoms', 'N_rotatable_bonds', 'LE', 'N_interactions', 'N_interactions_lost', '∆∆G', 'max_hit_Tanimoto', 'N_HA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71047b4-77f5-4daa-bcb0-0996a3ae3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = valids.sort_values('ad_hoc_penalty').drop_duplicates('cluster').drop_duplicates('locs')\n",
    "valids.loc[f.index, 'filtered'] = True\n",
    "valids.filtered.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0019c7-87d8-40db-a451-f0c558214942",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids['has_S1_pocket'] = valids[['hbond:THR:142', 'hbond:HIS:161', 'pistack:HIS:161', 'halogenbond:THR:142']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c912fb-4f13-4842-ba1f-f3f8705a7a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4b913-61f7-4929-999f-af4256cfd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# , ('S2', 'ridge')\n",
    "\n",
    "# PV-002509590804# \n",
    "\n",
    "f = valids.loc[valids.locs.isin([('S1', 'S2'), ('S1', 'ridge')]) &\n",
    "               (valids.has_S1_pocket >= 2)\n",
    "              ]\\\n",
    "           .sort_values('ad_hoc_penalty')\\\n",
    "           .drop_duplicates('cluster')\\\n",
    "           .head(50)\n",
    "valids.loc[f.index, 'filtered'] = True\n",
    "f[['name', 'hit_names', 'ad_hoc_penalty', 'locs', '∆∆G', 'LE', 'comRMSD', 'N_rotatable_bonds', 'LE', 'N_interactions', 'N_interactions_lost', '∆∆G', 'max_hit_Tanimoto', 'N_HA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254915a-9abf-4479-a6d3-1be295984c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# , ('S2', 'ridge')\n",
    "f = valids.loc[valids.locs.isin([('S2', 'ridge')]) & (valids['∆∆G'] <= -4)]\\\n",
    "           .sort_values('ad_hoc_penalty')\\\n",
    "           .drop_duplicates('cluster')\\\n",
    "           .head(10)\n",
    "valids.loc[f.index, 'filtered'] = True\n",
    "f[['name', 'hit_names', 'ad_hoc_penalty', 'locs', '∆∆G', 'LE', 'comRMSD', 'N_rotatable_bonds', 'LE', 'N_interactions', 'N_interactions_lost', '∆∆G', 'max_hit_Tanimoto', 'N_HA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23fc0cf-d8ba-4e76-9f08-d8af2697a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.filtered.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1221fc-6aba-41f3-9ab6-f07800957903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worse case\n",
    "sanity_mask = (valids['N_rotatable_bonds'] <= 6) & \\\n",
    "              (valids['LE'] >= 0.1) & \\\n",
    "              (valids['∆∆G'] <= -3) & \\\n",
    "              (valids['N_interactions'] >= 2) & \\\n",
    "              (valids['N_interactions_lost'] <= 1) & \\\n",
    "              (valids['max_hit_Tanimoto'] <= 0.4) & \\\n",
    "              (valids['N_unconstrained_atoms'] < valids['N_constrained_atoms'])\n",
    "\n",
    "display(valids.loc[sanity_mask].filtered.value_counts())\n",
    "\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "PandasTools.WriteSDF(valids.loc[sanity_mask & valids.filtered],\n",
    "                     'autoshort-fragmenstein.sdf',\n",
    "                      molColName='minimized_mol', idName='name',\n",
    "                     properties=['hit_names', '∆∆G', 'LE', 'comRMSD', 'locs', 'N_HA', 'ad_hoc_penalty', 'N_rotatable_bonds', 'LE', 'N_interactions', 'N_interactions_lost', 'max_hit_Tanimoto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382910f-8fc3-48e7-ac45-cfc40fbe0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = valids.loc[sanity_mask & valids.filtered].reset_index(drop=True)\\\n",
    "            .rename(columns={'smiles': 'SMILES', \n",
    "                             'name': 'Vendor_ID',\n",
    "                             'hit_names': 'Fragment_inspiration_nums',\n",
    "                            })\n",
    "\n",
    "sub['Fragalysis_link'] = ''\n",
    "sub['ZINC_ID'] = 'REAL'\n",
    "sub['Vendor'] = 'Enamine'\n",
    "sub['Inventor_surname'] = 'Ferla'\n",
    "sub['Confidence'] = 1\n",
    "sub['Method_to_produce'] = 'mergers'\n",
    "sub['Comments'] = 'Site filtered. Analogue enumerated. Fragmestein mergers. Multiple filters.'\n",
    "sub['SDF_filename(emailed)'] = 'https://github.com/matteoferla/EV-D68-3C-protease/blob/main/03_merge-fragmenstein/autoshort-fragmenstein.sdf'\n",
    "sub['Notes_filename(emailed)'] = 'https://github.com/matteoferla/EV-D68-3C-protease/blob/main/03_merge-fragmenstein/fragpipe.ipynb'\n",
    "\n",
    "sub = sub[['SMILES',\n",
    " 'Fragment_inspiration_nums',\n",
    " 'Fragalysis_link',\n",
    " 'Confidence',\n",
    " 'Inventor_surname',\n",
    " 'Method_to_produce',\n",
    " 'Comments',\n",
    " 'ZINC_ID',\n",
    " 'Vendor',\n",
    " 'Vendor_ID',\n",
    " 'SDF_filename(emailed)',\n",
    " 'Notes_filename(emailed)']].to_csv('autoshort-fragmenstein.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253d9bd-0ff4-4285-8b2a-7a89755de014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f03d6f-6d26-4a04-89ef-51b3aab362b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8f96f-0409-459a-b839-4e18721e40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.filtered.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd826344-6899-4ae6-9b90-cf87bea330fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d8753-f23e-402f-b7ae-154ba102a7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
